{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BethwelKimutai/Imageclassifier/blob/main/appEcosentinel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfwWfPWu-0J3",
        "outputId": "d40b67f4-1d0b-4d17-c855-db28c49799eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "xidVy5IPtcna"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set data directory\n",
        "train_dir = '/content/drive/MyDrive/data'\n",
        "valid_dir = '/content/drive/MyDrive/data'\n",
        "test_dir = '/content/drive/MyDrive/data'"
      ],
      "metadata": {
        "id": "hckwStvU7itS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the data directory\n",
        "datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "bQ4Oavid_6qK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import imghdr"
      ],
      "metadata": {
        "id": "v7ATrwf5H_Q3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_exts = ['jpeg','jpg','bmp','png']"
      ],
      "metadata": {
        "id": "IynOgRTXIHGT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_exts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vky-5VgoIbjN",
        "outputId": "232b0cd5-07f3-456c-f21b-62b130278ddb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jpeg', 'jpg', 'bmp', 'png']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "QIDBcl2SI4KK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class in os.listdir('/content/drive/MyDrive/data'):\n",
        "    for image in os.listdir(os.path.join('/content/drive/MyDrive/data',image_class)):\n",
        "        image_path = os.path.join('/content/drive/MyDrive/data', image_class, image)\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            tip = imghdr.what(image_path)\n",
        "            if tip not in image_exts:\n",
        "                print('image not in ext list{}'.forma(image_path))\n",
        "                os.remove(image_path)\n",
        "        except Exception as e :\n",
        "            print('Issue with image{}'.format(image_path))\n",
        "            #os.remove(image_path)"
      ],
      "metadata": {
        "id": "zphzdp23IpVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "def process_images(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                if os.path.isdir(file_path):\n",
        "                    # Remove directories\n",
        "                    shutil.rmtree(file_path)\n",
        "                    print(f\"Removed directory: {file_path}\")\n",
        "                else:\n",
        "                    # Process image files\n",
        "                    try:\n",
        "                        img = Image.open(file_path)\n",
        "                        img.verify()  # Verify image integrity\n",
        "\n",
        "                        # Perform further processing or save the modified image if needed\n",
        "                        # ...\n",
        "\n",
        "                    except (IOError, SyntaxError, UnidentifiedImageError):\n",
        "                        # Remove problematic image file\n",
        "                        os.remove(file_path)\n",
        "                        print(f\"Removed: {file_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file: {file_path}\")\n",
        "                print(str(e))\n",
        "\n",
        "# Provide the directory path containing the images\n",
        "directory_path = \"/content/drive/MyDrive/data\"\n",
        "process_images(directory_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX0EGMdgQLyq",
        "outputId": "f89b5057-9fd5-4731-b9c8-94a6929c62ac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector6.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector8.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector13.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector2.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/192px.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector11.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector9.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector14.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector7.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector10.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector5.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector3.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector4.svg\n",
            "Removed: /content/drive/MyDrive/data/52.Pericopsis elata (African Teak)/vector12.svg\n",
            "Removed: /content/drive/MyDrive/data/27.Ekebergia capensis (Cape Ash)/Ekebergia-capensis-tree.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224), # Resize input images to 224x224 pixels\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad6igSamAuYl",
        "outputId": "0c24ea51-d3e0-4cf7-d149-df891020c208"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12510 images belonging to 101 classes.\n",
            "Found 12510 images belonging to 101 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building the model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(101, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "JomOEw7bB9bB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "g0Q0C8GjCRXN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          epochs=10,\n",
        "          validation_data=valid_generator)\n",
        "\n",
        "# Evaluate the model\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN2QZgy0CfDm",
        "outputId": "5c89aac9-ef6d-46a8-ba53-f99038aefa9d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 412s 1s/step - loss: 0.3904 - accuracy: 0.7886 - val_loss: 0.3411 - val_accuracy: 0.8114\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 474s 1s/step - loss: 0.3740 - accuracy: 0.7894 - val_loss: 0.3281 - val_accuracy: 0.8110\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 411s 1s/step - loss: 0.3595 - accuracy: 0.7960 - val_loss: 0.3303 - val_accuracy: 0.8114\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 411s 1s/step - loss: 0.3597 - accuracy: 0.7907 - val_loss: 0.3351 - val_accuracy: 0.8121\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 408s 1s/step - loss: 0.3836 - accuracy: 0.7845 - val_loss: 0.3323 - val_accuracy: 0.8124\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 407s 1s/step - loss: 0.3765 - accuracy: 0.7926 - val_loss: 0.3284 - val_accuracy: 0.8121\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 406s 1s/step - loss: 0.3602 - accuracy: 0.7908 - val_loss: 0.3196 - val_accuracy: 0.8121\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 470s 1s/step - loss: 0.3481 - accuracy: 0.7933 - val_loss: 0.3279 - val_accuracy: 0.8129\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 410s 1s/step - loss: 0.3480 - accuracy: 0.7884 - val_loss: 0.3143 - val_accuracy: 0.8126\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 410s 1s/step - loss: 0.3401 - accuracy: 0.7888 - val_loss: 0.3213 - val_accuracy: 0.8123\n",
            "Found 12510 images belonging to 101 classes.\n",
            "391/391 [==============================] - 204s 521ms/step - loss: 0.3213 - accuracy: 0.8123\n",
            "Test loss: 0.3213460445404053\n",
            "Test accuracy: 0.8123101592063904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming you have a trained model called 'model'\n",
        "\n",
        "# Convert the model to TFLite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to a file\n",
        "tflite_model_file = 'model.tflite'\n",
        "with open(tflite_model_file, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"TFLite model saved successfully.\")\n"
      ],
      "metadata": {
        "id": "LHfqjbKgWK0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a4889b-ad63-45e5-956b-8c8cd77e7cf7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFLite model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnvsD8i-a4qW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}