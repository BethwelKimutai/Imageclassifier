{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOP6b8FUd0TPn5/xNYP7ToO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BethwelKimutai/Imageclassifier/blob/main/Ecosentinel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfwWfPWu-0J3",
        "outputId": "6e0147c9-cab1-4b34-cfd8-32e406741a00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "xidVy5IPtcna"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set data directory\n",
        "train_dir = '/content/drive/MyDrive/data'\n",
        "valid_dir = '/content/drive/MyDrive/data'\n",
        "test_dir = '/content/drive/MyDrive/data'"
      ],
      "metadata": {
        "id": "hckwStvU7itS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the data directory \n",
        "datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "bQ4Oavid_6qK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224), # Resize input images to 224x224 pixels\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad6igSamAuYl",
        "outputId": "7d3a77ee-ddc5-4678-c39f-0b18cd1ae397"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 247 images belonging to 2 classes.\n",
            "Found 247 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building the model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "JomOEw7bB9bB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "g0Q0C8GjCRXN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          epochs=2,\n",
        "          validation_data=valid_generator)\n",
        "\n",
        "# Evaluate the model\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN2QZgy0CfDm",
        "outputId": "d1f9cdc7-06da-4ba5-e2b8-fb183374601f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "8/8 [==============================] - 34s 3s/step - loss: 1.2039 - accuracy: 0.4737 - val_loss: 0.6272 - val_accuracy: 0.6518\n",
            "Epoch 2/2\n",
            "8/8 [==============================] - 11s 2s/step - loss: 0.6191 - accuracy: 0.6721 - val_loss: 0.5352 - val_accuracy: 0.8138\n",
            "Found 247 images belonging to 2 classes.\n",
            "8/8 [==============================] - 6s 658ms/step - loss: 0.5352 - accuracy: 0.8138\n",
            "Test loss: 0.535179615020752\n",
            "Test accuracy: 0.8137651681900024\n"
          ]
        }
      ]
    }
  ]
}